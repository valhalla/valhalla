#!/usr/bin/env python3

import argparse
import os
from collections import namedtuple
from functools import partial
import gzip
import json
import logging
from math import ceil, floor
from multiprocessing import cpu_count
from multiprocessing.dummy import Pool as ThreadPool
from pathlib import Path
import sys
from typing import List, Iterable, Set
from urllib import request
from urllib.error import URLError

description = """Downloads Tilezen's elevation tiles that either intersect with features in all .geojson files in
              --input-geojson-dir or that intersect with --bbox. NOTE: geojson method requires shapely.
              """

# set up the logger basics
LOGGER = logging.getLogger(__name__)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)5s: %(message)s"))
LOGGER.addHandler(handler)

parser = argparse.ArgumentParser(description=description)
method = parser.add_mutually_exclusive_group()
method.add_argument(
    "-g",
    "--from-geojson",
    help="Absolute or relative path to directory with .geojson files used "
    "as input to tile intersection. Requires shapely.",
    type=Path,
)
method.add_argument(
    "-b",
    "--from-bbox",
    help="Bounding box coordinates in the format 'minX,minY,maxX,maxY'.",
    type=str,
)
method.add_argument(
    "-t",
    "--from-tiles",
    help="Only download tiles covered by the Valhalla graph.",
    action="store_true"
)
parser.add_argument(
    "-c",
    "--config",
    help="Absolute or relative path to the Valhalla config JSON.",
    type=Path,
)
parser.add_argument(
    "-p", "--parallelism",
    help="Number of processing units to use.",
    type=int,
    default=cpu_count()
)
parser.add_argument(
    "-d",
    "--decompress",
    help="If set, downloaded files will be decompressed.",
    action="store_true",
)
parser.add_argument(
    "-v",
    "--verbosity",
    help="Accumulative verbosity flags; -v: INFO, -vv: DEBUG",
    action="count",
    default=0,
)

Tile = namedtuple("Tile", ["name", "dir"])
LOCAL_SIZE = 0.25


def get_tile_info(
    x: int,
    y: int,
) -> Tile:
    hemisphere = "S" if y < 0 else "N"
    dir_name = "%s%02d" % (hemisphere, abs(y))
    tile_name = "%s%02d%s%03d.hgt" % (
        hemisphere,
        abs(y),
        "W" if x < 0 else "E",
        abs(x),
    )

    return Tile(tile_name, dir_name)


def grid_from_bounds(bounds: List[float]) -> List[List[int]]:
    """Creates a regular grid of size 1x1 within specified bounds"""
    # expand bbox by snapping to a 1 x 1 degree grid
    # loop through x and y range and create the grid
    min_x, min_y = [floor(x) for x in bounds[:2]]
    max_x, max_y = [ceil(x) for x in bounds[-2:]]
    for x in range(min_x, max_x):
        for y in range(min_y, max_y):
            yield [x, y, x + 1, y + 1]


def get_tiles_with_geojson(input_dir: Path) -> Set[Tile]:
    try:
        from shapely.geometry import Polygon, box
    except ImportError:
        LOGGER.critical(
            "Could not import shapely. Please install shapely or use another download method instead."
        )
        sys.exit(1)

    if not input_dir.is_dir() or not len(list(input_dir.glob('*.geojson'))) > 0:
        LOGGER.critical(f"Geojson directory does not exist or contains no GeoJSON files: {input_dir.resolve()}")
        sys.exit(1)

    def get_outer_rings(input_dir: Path) -> Iterable[Polygon]:
        for file in input_dir.glob("*.geojson"):
            with open(file) as f:
                geojson = json.load(f)
            for feature in geojson["features"]:
                if feature["geometry"]["type"] == "Polygon":
                    yield Polygon(feature["geometry"]["coordinates"][0])
                if feature["geometry"]["type"] == "MultiPolygon":
                    for single_polygon in feature["geometry"]["coordinates"]:
                        yield Polygon(single_polygon[0])

    tile_infos = set()
    for poly in get_outer_rings(input_dir):
        for rect in grid_from_bounds(poly.bounds):
            if poly.intersects(box(*rect)):
                tile_x, tile_y, *_ = rect
                tile_infos.add(get_tile_info(tile_x, tile_y))

    return tile_infos


def get_tiles_with_bbox(bbox_str: str) -> Set[Tile]:
    try:
        bbox = min_x, min_y, max_x, max_y = [float(x) for x in bbox_str.split(",")]
    except ValueError:
        LOGGER.critical(f"BBOX {bbox_str} is not a comma-separated string of coordinates.")
        sys.exit(1)

    # validate bbox
    if (
        min_x > max_x
        or min_x < -180
        or max_x > 180
        or min_y > max_y
        or min_y < -90
        or max_y > 90
    ):
        LOGGER.critical(f"Bbox invalid: {bbox}")
        sys.exit(1)

    LOGGER.debug(f"Received valid bbox: {bbox}")

    tile_infos = set()
    for grid in grid_from_bounds(bbox):
        tile_x, tile_y = grid[:2]
        tile_infos.add(get_tile_info(tile_x, tile_y))

    return tile_infos


def get_tiles_with_graph(graph_dir: Path) -> Set[Tile]:
    if not graph_dir.is_dir():
        LOGGER.critical(f"Graph directory {graph_dir.resolve()} does not exist.")
        sys.exit(1)

    tile_infos = set()
    local_dir = graph_dir.joinpath('2')
    tile_width = int(360 / LOCAL_SIZE)
    for tile_fp in local_dir.rglob('*.gph'):
        # turn the path into a tile ID
        tile_id = int(str(tile_fp.parent.relative_to(local_dir).joinpath(tile_fp.stem)).replace(os.sep, ''))
        tile_x, tile_y = floor(int(tile_id % tile_width) * LOCAL_SIZE - 180), floor(int(tile_id / tile_width) * LOCAL_SIZE - 90)

        tile_infos.add(get_tile_info(tile_x, tile_y))

    return tile_infos


def download(tile: Tile, output_dir, decompress):
    dest_directory = Path(output_dir, tile.dir)
    dest_directory.mkdir(parents=True, exist_ok=True)

    filepath = dest_directory.joinpath(tile.name + (".gz" if not decompress else ""))
    if filepath.is_file():
        return False

    url = (
        f"http://s3.amazonaws.com/elevation-tiles-prod/skadi/{tile.dir}/{tile.name}.gz"
    )

    LOGGER.info(f"Downloading tile {tile.name}")
    try:
        with request.urlopen(url) as res, open(filepath, "wb") as f:
            if decompress:
                with gzip.GzipFile(fileobj=res, mode="rb") as gz:
                    f.write(gz.read())
            else:
                f.write(res.read())
            LOGGER.debug(f"Successfully downloaded tile {tile.name}")

        return True
    except URLError as e:
        LOGGER.critical(f"Download failed of elevation tile {tile.dir}/{tile.name}: {e.reason}")
        return False


if __name__ == "__main__":
    args = parser.parse_args()
    with open(args.config) as f:
        config = json.load(f)
    elevation_fp = Path(config["additional_data"]["elevation"] or "elevation")

    # set the right logger level
    if args.verbosity == 0:
        LOGGER.setLevel(logging.CRITICAL)
    elif args.verbosity == 1:
        LOGGER.setLevel(logging.INFO)
    elif args.verbosity >= 2:
        LOGGER.setLevel(logging.DEBUG)

    if args.from_geojson:
        tiles = get_tiles_with_geojson(args.from_geojson)
    elif args.from_bbox:
        tiles = get_tiles_with_bbox(args.from_bbox)
    elif args.from_tiles:
        tiles = get_tiles_with_graph(Path(config["mjolnir"]["tile_dir"]))
    else:
        LOGGER.critical("No download method specified.")
        sys.exit(1)

    LOGGER.debug(sorted(tiles, key=lambda x: x.name))

    # create the threadpool and download
    pool = ThreadPool(args.parallelism)
    results = pool.imap_unordered(
        partial(download, output_dir=elevation_fp, decompress=args.decompress), tiles
    )

    sum_downloaded = list(filter(lambda res: res is True, results))
    LOGGER.info(f"Downloaded {len(sum_downloaded)} tiles. Exiting.")
